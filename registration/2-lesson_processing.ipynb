{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;font-size: 40pt\">Point cloud processing</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden custom latex commands here $ \\curvearrowright$\n",
    "\n",
    "----\n",
    "[comment]: <> (General commands)\n",
    "$\\DeclareMathOperator*{\\argmin}{arg\\,min}$\n",
    "$\\DeclareMathOperator{\\error}{error}$\n",
    "$\\DeclareMathOperator*{\\match}{match}$\n",
    "$\\DeclareMathOperator{\\distance}{d}$\n",
    "$\\DeclareMathOperator{\\outlier}{outlier}$\n",
    "$\\DeclareMathOperator{\\weight}{w}$\n",
    "$\\DeclareMathOperator{\\datafilter}{datafilter}$\n",
    "$\\newcommand{\\mat}[1]{\\mathbf{#1}}$\n",
    "$\\newcommand{\\point}[2][]{{}^{#1}\\mathbf{#2}}$\n",
    "$\\newcommand{\\frame}[1]{\\mathcal{#1}}$\n",
    "$\\newcommand{\\shape}[2][]{{}^{#1}\\mathcal{#2}}$\n",
    "$\\newcommand{\\matches}[1]{\\mathcal{#1}}$\n",
    "$\\newcommand{\\transformation}[3][T]{{}_{#2}^{#3}\\mat{#1}}$\n",
    "$\\newcommand{\\weights}[1]{\\mathcal{#1}}$\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The different types of <tt>data filters</tt> try to augment the distinctiveness of the inputs usually by reducing the number of features and by augmenting the dimension of either the features or the descriptors.\n",
    "For example, a black and white image has a uniform distribution of features (a grid) and one dimension descriptor (the intensity) associated to each feature. \n",
    "After some <tt>data filters</tt> are applied, only few points in the image will be kept as features and the descriptors will be increased with information from neighboring pixels, for example to 64 dimensions when using Scale Invariant Feature Transform (SIFT) descriptors [[Lowe, 2004]](https://link.springer.com/article/10.1023%2FB%3AVISI.0000029664.99615.94).\n",
    "In the case of a point cloud, it might be necessary to extract surface normal vectors (*feature enhancement*), while uniformizing the density of points (*features reduction*).\n",
    "This can also be viewed as *lossy data compression*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Enhancement\n",
    "When only geometric information is available, there are still ways to extract some level of distinctness by using differential geometry.\n",
    "We shortly introduce key concepts related to the use of geometric information.\n",
    "In this work, the notion of a shape $\\shape{S}$ is used as a representation of a generic object in the Euclidean space with a certain set of properties.\n",
    "For example, those properties can be photometric, thermic, and semantic. \n",
    "Simple shapes, such as points, lines, quadrics, can be easily parametrized but most of the shapes encountered in the a real environment are too complex to be completely synthesized with parameters.\n",
    "To allow a certain representation of the world, a complex shape $\\shape{S}$ can be approximated by a set of other shapes only if they can be expressed in the same frame of reference $\\frame{F}$.\n",
    "\n",
    "Sensors measuring depth produce such approximations by discretizing the environment in a set of points. \n",
    "From smooth areas defined by those points, we present five types of primitives that can be extracted based on Differential Geometry: point, line, plane, curve and quadric.\n",
    "The first derivative group rely on normal vectors $n$ (i.e. orthogonal to a line or plane) and tangent vectors $t$ (i.e. parallel to a line or plane) to express the area.\n",
    "Since they are defined with respect to a point $\\point{p}$, normal and tangent vectors can be represented with a minimal set of 2 angles in polar coordinates.\n",
    "Normal and tangent vectors can be seen as a dual representation.\n",
    "The choice of using either one or the other is defined by the minimum information required to express a primitive.\n",
    "In the case of a line in 3D, the normal vectors needs to define a plane perpendicular to that line. \n",
    "Therefore, only using the tangent vector is more convenient.\n",
    "The same reasoning holds for using a normal vector for the surface.\n",
    "The notion of direction also needs to be defined depending of the primitive.\n",
    "It is reasonable to use unsigned direction in the case of tangents and signed direction in the case of normals where positive sign defined the outer surface of the shape.\n",
    "The motivation behind this choice is that we want to keep track of which side of a surface we are measuring while moving.\n",
    "In the 2D case, it is equivalent to represent a line by a tangent or a normal in term of the number of parameters.\n",
    "However, it is usually assumed that the perceived 2D plane cuts perpendicular surfaces, so it makes more sense to use normal vector to also track the outer side of the line.\n",
    "[Figure 2.2](#2d_lines) illustrates this choice of representation for the 2D case.\n",
    "Viewpoints $v_n$ (i.e., where the sensor was when a point $\\point{p}$ was measured on a surface $\\shape{S}$) are used to determine the direction of the normal vectors $n$, whereas no extra information is needed for a tangent vector $t$ laying on a line that can be observed from both sides.\n",
    "<p id=\"2d_lines\" style=\"text-align: center;\">\n",
    "    <img src=\"images/normals.png\" width=\"36.75%\"/>\n",
    "    <img src=\"images/tangents.png\" width=\"36.75%\"/> <br/>\n",
    "    <b>Figure 2.2:</b> Difference between using normal vectors and tangent vectors to represent a 2D shape.\n",
    "    <em>Left</em>: The 2D line is known to be measured from a volume, which can only view from one side as illustrated with the black arrows $v_1$ and $v_2$.\n",
    "    The direction of the surface make sense to be encoded in its representation leading to the choice of normal vectors $n$ (dashed blue arrow).\n",
    "    <em>Right</em>: The same line can be observe from both direction leading to the selection of an undirected tangent vector $t$ (dashed blue line).\n",
    "</p>\n",
    "\n",
    "As for the second derivative group, a curve is parametrized by a curvature $\\kappa$ (a scalar) representing an osculating circle parallel to the tangent of a line. \n",
    "In the case of a quadric (i.e. a curved surface), it is parametrized by principal direction vectors $t_{min}$, $t_{max}$ and the principal curvature scalars $\\kappa_{min}, \\kappa_{max}$.\n",
    "Those principal directions rely on a point $\\point{p}$ and on the normal vector $n$, so they could be expressed only with one angle.\n",
    "In other words, the principal directions are tangent vectors to the surface complementing the normal vector.\n",
    "In the case of curves, the curvature is always positive as opposed to quadrics for which a positive $\\kappa$ means that the surface bend in the same direction of the normal vector and vice-versa.\n",
    "For simplicity in further computation, most of the publications use normalized 3D vectors to express normals and tangents leading to a larger set of parameters, as shown in [Table 2.1](#primitivesParameters).\n",
    "<p id=\"primitivesParameters\" style=\"text-align: center;\">\n",
    "    <b>Table 2.1:</b> Comparison of different parametrizations used to represent geometric primitives. <br/>\n",
    "    Minimum parametrization\n",
    "</p>\n",
    "\n",
    "| *Name* | &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *Parameters* &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | &nbsp;&nbsp;&nbsp; *Constraints* &nbsp;&nbsp;&nbsp; | *Reference* |\n",
    "|:--------------------:|:--------------------------------------------------------:|:-------------------------------------------------------:|:------------------:|\n",
    "|         Point        |                 $\\point{p} = \\{x, y, z\\}$                |               $\\point{p} \\in \\mathbb{R}^3$              |     $\\frame{F}$    |\n",
    "|        Tangent       |                  $t = \\{\\theta, \\phi \\}$                 |                $\\theta \\in [ -\\pi, \\pi )$               |     $\\frame{F}$    |\n",
    "|                      |                                                          |      $\\phi \\in [ -\\frac{\\pi}{2}, \\frac{\\pi}{2} ]$       |                    |\n",
    "|        Normal        |                  $n = \\{\\theta, \\phi \\}$                 |                $\\theta \\in [ -\\pi, \\pi )$               |     $\\frame{F}$    |\n",
    "|                      |                                                          |      $\\phi \\in [ -\\frac{\\pi}{2}, \\frac{\\pi}{2} ]$       |                    |\n",
    "| Principal Directions |                          $\\psi$                          |                 $\\psi \\in [ -\\pi, \\pi )$                | $\\{n, \\frame{F}\\}$ |\n",
    "|       Curvature      |                         $\\kappa$                         |                 $\\kappa \\in \\mathbb{R}_+$               |     $\\frame{F}$    |\n",
    "| Principal Curvatures | $\\kappa = \\{\\kappa_\\mathrm{min}, \\kappa_\\mathrm{max} \\}$ | $\\kappa \\in \\mathbb{R}^2$ | $\\{n, \\frame{F}\\}$ |\n",
    "\n",
    "<p style=\"text-align: center;\">Typical parametrization</p>\n",
    "\n",
    "|                      |                                                         |                                 |                    |\n",
    "|:--------------------:|:-------------------------------------------------------:|:-------------------------------:|:------------------:|\n",
    "|         Point        |                $\\point{p} = \\{x, y, z\\}$                |   $\\point{p} \\in \\mathbb{R}^3$  |     $\\frame{F}$    |\n",
    "|        Tangent       |                 $t = \\{t_x, t_y, t_z\\}$                 |            $|t| = 1$            |     $\\frame{F}$    |\n",
    "|        Normal        |                 $n = \\{n_x, n_y, n_z\\}$                 |            $|n| = 1$            |     $\\frame{F}$    |\n",
    "| Principal Directions |      $\\gamma = \\{t_\\mathrm{min}, t_\\mathrm{max}\\}$      | $n \\perp t_{min} \\perp t_{max}$ |     $\\frame{F}$    |\n",
    "|       Curvature      |                         $\\kappa$                        |    $\\kappa \\in \\mathbb{R}_+$    |     $\\frame{F}$    |\n",
    "| Principal Curvatures | $\\kappa = \\{\\kappa_\\mathrm{min}, \\kappa_\\mathrm{max}\\}$ |    $\\kappa \\in \\mathbb{R}^2$    | $\\{n, \\frame{F}\\}$ |\n",
    "\n",
    "Those parameters (point, tangent, normal, principal direction, curvature, and principal curvatures) bring us to a group of parametrized primitives (point, line, plane, curve and quadric), which can be helpful to approximate other complex 3D shapes. \n",
    "Those geometric primitives are listed in [Table 2.2](#primitivesDef) with their characteristics.\n",
    "A graphical representation of those primitive is also showed in [Figure 2.3](#approximation1D) in the case of a shape considered as a 1D manifold and in [Figure 2.4](#approximation2D) in the case of a 2D manifold.\n",
    "In their current configuration, lines, planes, curves and quadrics are unbounded, which means that they can reach infinity on their unconstrained direction. \n",
    "One can constrain a primitive by using a primitive with a lower dimensionality [[Besl, 1988]](https://ieeexplore.ieee.org/document/5966). \n",
    "Thus, a plane can be bounded by a set of lines, a line can be bounded by a set of points, etc. \n",
    "<p id=\"primitivesDef\" style=\"text-align: center;margin-left: 25%;margin-right: 25%;\">\n",
    "    <b>Table 2.2:</b> Characteristics of primitives used for shape approximations.\n",
    "    The number in parenthesis of the column <em>Nb Param.</em> corresponds to the minimum number of parameters that can be used to express the same primitive.\n",
    "</p>\n",
    "\n",
    "| *Primitives* | &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *Parameters* &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; | *Derivative* | *Manifold* | *Bound* | *Nb Param.* |\n",
    "|:------------:|:------------------------------------------:|:------------:|:----------:|:-----------:|:-----------:|\n",
    "|     Point    |                 $\\point{p}$                |       0      |      0     |      -      |     3(3)    |\n",
    "|     Line     |          $\\mathcal{L} = \\{ p, t\\}$         |       1      |      1     |    point    |     6(5)    |\n",
    "|     Plane    |             $\\Phi = \\{ p, n \\}$            |       1      |      2     | line, curve |     6(5)    |\n",
    "|     Curve    |    $\\mathcal{C} = \\{ p, t, n, \\kappa \\}$   |       2      |      1     |    point    |    10(7)    |\n",
    "|    Quadric   | $\\mathcal{Q} = \\{ p, n, \\gamma, \\kappa \\}$ |       2      |      2     | line, curve |    14(8)    |\n",
    "\n",
    "<p id=\"approximation1D\" style=\"text-align: center;\">\n",
    "    <img src=\"images/primitive1D.jpg\" width=\"50%\"/> <br/>\n",
    "    <b>Figure 2.3:</b> Representations of a complex shape approximated as a 1D manifold.\n",
    "    Representations (in dark blue) of a complex shape $\\shape{S}$ (in light gray) approximated as a 1D manifold.\n",
    "    <em>Left</em>: no derivative (point).\n",
    "    <em>Middle</em>: first derivative (line).\n",
    "    <em>Right</em>: second derivative (curve).\n",
    "</p>\n",
    "\n",
    "<p id=\"approximation2D\" style=\"text-align: center;\">\n",
    "    <img src=\"images/primitive2D.jpg\" width=\"50%\"/> <br/>\n",
    "    <b>Figure 2.4:</b> Representations of a complex shape approximated as a 1D manifold.\n",
    "    Representations (in dark blue) of a complex shape $\\shape{S}$ (in light gray) approximated as a 2D manifold.\n",
    "    <em>Left</em>: no derivative (point).\n",
    "    <em>Middle</em>: first derivative (plane).\n",
    "    <em>Right</em>: second derivative (quadric).\n",
    "</p>\n",
    "\n",
    "At a higher level of organization, a group of geometric primitives can be processed without any proximity assumption (*unstructured*) or with some smoothness constrains (*structured*).\n",
    "Examples of representation for a 1D manifold is a spline, while for a 2D manifold a mesh or Non-uniform rational B-spline (NURBS) can be used.\n",
    "When it comes to a noisy group of points, tensor voting [[Medioni et al., 2000]](http://www.sci.utah.edu/~gerig/CS7960-S2010/handouts/Medioni_tensor_voting.pdf) can be used to interpolate shape on a dense 3D grid.\n",
    "The voting results can then be later process to extract 1D and 2D manifolds out of the dense volume.\n",
    "\n",
    "Higher derivatives could also approximate a shape at one point with more precision. \n",
    "Unfortunately, high derivatives are very sensitive to noise when applied outside of a theoretical context.\n",
    "In this review, we limit ourselves to the second derivative given that a non-negligible noise level is expected from the sensor measurements and from the motion of the sensor.\n",
    "As shown in [[Pomerleau et al., 2012a]](https://ieeexplore.ieee.org/document/6473358), even the first derivative needs a large supporting surface to overcome the sensor noise of typical laser rangefinders.\n",
    "For example, extracting the surface normal from a flat area of 10-cm radius already leads to an expected error of 1.6$^\\circ$ (0.03 rad) for the rangefinder Sick LMS-151.\n",
    "This is one of the characteristics of robotic applications when it comes to selecting a surface parametrization.\n",
    "The ratio of noise to signal is often higher in robotics than in object modeling, thus rendering many complex modeling algorithms ineffective.\n",
    "This could explain why most registration algorithms applied to robotics tend to select a shape representation very close to the raw measurements (i.e., points) instead of relying on faulty surface reconstruction.\n",
    "\n",
    "## Sensitivity to transformation functions\n",
    "The shape representations are affected differently by transformation functions.\n",
    "At a more generic level, transformation functions affect geometric quantities.\n",
    "Examples of quantities are: coordinate, orientation, length, angle, and length ratio.\n",
    "Those geometric quantities with examples of associated primitives are listed in [Table 2.3](#transformationQuanties).\n",
    "As examples of lengths, we used $\\kappa$, which is the inverse of a radius, and the eigenvalues $\\lambda$, which define a scale over a vector.\n",
    "Having geometric parameters invariant to as many transformations as possible helps the matching function during registration because the association will be less sensitive to large initial alignment error.\n",
    "[Table 2.4](#influenceFunc) relates the different geometric quantities to the basic transformation functions affecting them.\n",
    "<p id=\"transformationQuanties\" style=\"text-align: center;margin-left: 25%;margin-right: 25%;\">\n",
    "    <b>Table 2.3:</b> Examples of geometric quantities susceptible to be affected by a transformation function.\n",
    "</p>\n",
    "\n",
    "|  *Quantity*  |    &nbsp; *Single Entity* &nbsp;    |     *Relationship in a Set*    |\n",
    "|:------------:|:-----------------------------------:|:------------------------------:|\n",
    "|  Coordinate  |             $\\point{p}$             |                -               |\n",
    "|  Orientation | $n, t_\\mathrm{min}, t_\\mathrm{max}$ |                -               |\n",
    "|    Length    |          $\\kappa, \\lambda$          |         $||p_a - p_b||$        |\n",
    "|     Angle    |                  -                  | $\\text{arccos}(n_a \\cdot n_b)$ |\n",
    "| Length Ratio |                  -                  |      $\\kappa_a / \\kappa_b$     |\n",
    "\n",
    "<p id=\"influenceFunc\" style=\"text-align: center;margin-left: 25%;margin-right: 25%;\">\n",
    "    <b>Table 2.4:</b> Influence of a transformation function on quantities defining a geometric primitive.\n",
    "    Influence of a transformation function on quantities defining a geometric primitive.\n",
    "    Cells marked with a \"X\" mean that the transformation affects the values of the entity.\n",
    "</p>\n",
    "\n",
    "|       *Function*       | *Coordinate* | *Length* | *Orientation* | *Angle* | *Length Ratio* |\n",
    "|:----------------------:|:------------:|:--------:|:-------------:|:-------:|:--------------:|\n",
    "|       Translation      |       X      |     -    |       -       |    -    |        -       |\n",
    "|     Uniform Scaling    |       X      |     X    |       -       |    -    |        -       |\n",
    "|        Rotation        |       X      |     -    |       X       |    -    |        -       |\n",
    "|   Nonuniform Scaling   |       X      |     X    |       X       |    X    |        -       |\n",
    "|          Shear         |       X      |     X    |       X       |    X    |        X       |\n",
    "|  Orthogonal Projection |       X      |     X    |       X       |    X    |        X       |\n",
    "| Perspective Projection |       X      |     X    |       X       |    X    |        X       |\n",
    "\n",
    "Most of the time, point cloud features come without external descriptors (i.e. as opposed to an image containing photometric information), so the proximity of other features is used to extend the shape approximation to support further derivatives. \n",
    "Surface orientations (or line orientations in 2D) are mainly used in literature [\\[Pulli, 1999](https://ieeexplore.ieee.org/document/805346), [Censi,\n",
    "2008](https://ieeexplore.ieee.org/document/4543181), [Bosse and Zlot, 2009b](https://ieeexplore.ieee.org/document/5152851), [Jost and Hugli, 2002](https://ieeexplore.ieee.org/document/1024114), [Schutz et al., 1998](https://ieeexplore.ieee.org/document/711852),\n",
    "[Jost and Hügli, 2002](https://link.springer.com/chapter/10.1007/3-540-45783-6_12), [Segal et al., 2009\\]](http://www.roboticsproceedings.org/rss05/p21.html). \n",
    "Line orientations are also used in image registration where the environment presents very few salient points when considering only intensity variation [[Stewart et al.,\n",
    "2003]](https://ieeexplore.ieee.org/document/1242341). \n",
    "Work based on surface normal vector distributions of surrounding points are also used by [Magnusson et al. [2009]](https://ieeexplore.ieee.org/document/5152538) and [Fairfield and Wettergreen [2009]](https://ieeexplore.ieee.org/document/5152688)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptor Enhancement\n",
    "A comparison of descriptors extracted from 2D point clouds can be found in [[Bosse and Zlot, 2009a]](https://www.sciencedirect.com/science/article/abs/pii/S0921889009000992).\n",
    "It is proposed that moment grid is better than 2D shape context, Gestalt, Hough transform peaks, orientation and projection histograms, and normal orientation histogram grid. \n",
    "Extension to the 2D shape context can be found in [[Tsai et al., 2010]](https://ieeexplore.ieee.org/document/5223602). \n",
    "Another study for 3D point clouds also concludes that moment grid is better than 3D shape context, spin image, shell image and local covariance [[Bosse and Zlot, 2009b]](https://ieeexplore.ieee.org/document/5152851).\n",
    "\n",
    "Usually, Iterative Closest Point (ICP) is done using only geometric features, but some works also present results using the intensity remission from an Hokuyo [[Yoshitaka et al., 2006]](https://ieeexplore.ieee.org/document/4153430) and from specialized system using three different wavelengths [[Godin et al., 1994]](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/2350/1/Three-dimensional-registration-using-range-and-intensity-information/10.1117/12.189139.short). \n",
    "Laser range finders are also combined with cameras to add color information to measured points [\\[Schutz et al., 1998](https://ieeexplore.ieee.org/document/711852), [Druon et al., 2006\\]](https://ieeexplore.ieee.org/document/4097937).\n",
    "When other sensors are used to provide descriptors, calibration is required.\n",
    "Interestingly, calibration also relies on registration solutions.\n",
    "Terrestrial survey scanners often have a calibrated camera associating color to 3D points, similar to RGB-D cameras.\n",
    "With the larger availability of photometric information, descriptors developed by the computer vision community can be used.\n",
    "In [[Tuytelaars and Mikolajczyk, 2008]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.7050&rep=rep1&type=pdf), characteristics of descriptive features are listed as *rotation*, *scale*, and *affine invariance*.\n",
    "Evaluation criteria are listed as *repeatability*, *distinctiveness*, *locality*, *quantity*, *accuracy*, and *efficiency*. \n",
    "In image registration, the list of most common tools for extracting descriptors are: Harris, Hessian, SUSAN, Harris-Laplace, Hessian-Laplace, DoG (SIFT), SURF, Harris-Affine, Hessian-Affine, Salient Regions, Edge-based, MSER, Intensity-based and Superpixel [[Tuytelaars and Mikolajczyk, 2008]](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.7050&rep=rep1&type=pdf).\n",
    "It is interesting to note that descriptors based on photometric information rely on passive illumination to ensure invariance.\n",
    "This assumption of illumination sources remaining static, which is mostly true for indoor lights, needs to be treated carefully for outdoor illumination, where the sun moves and clouds can shade light.\n",
    "Laser's intensity measurements are even more sensitive to transformation functions because the illumination source follows the sensor position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Reduction\n",
    "In applications using point clouds, features are sparse but not uniformly distributed. \n",
    "Nevertheless, the fact that sensors can provide a huge number of readings on a short period of time creates a bottleneck in term of computation power for the association as explained later.\n",
    "Several techniques are used to reduce the number of features: random sampling [\\[Jost and Hugli, 2002](https://ieeexplore.ieee.org/document/1024114), [Pan et al., 2010\\]](https://ieeexplore.ieee.org/document/5476132), uniform grid [\\[Magnusson et al., 2009](https://ieeexplore.ieee.org/document/5152538), [Bosse and Zlot, 2009b\\]](https://ieeexplore.ieee.org/document/5152851), grid projection [[Pan et al., 2010]](https://ieeexplore.ieee.org/document/5476132), octree [\\[Fairfield and Wettergreen, 2009](https://ieeexplore.ieee.org/document/5152688), [Wurm et al., 2010\\]](http://www2.informatik.uni-freiburg.de/~stachnis/pdf/wurm10icraws.pdf), and bounding box [\\[Stewart et al., 2003](https://ieeexplore.ieee.org/document/1242341), [Tsai et al., 2010\\]](https://ieeexplore.ieee.org/document/5223602). \n",
    "All these techniques reduce the number of features without considering their distinctiveness. \n",
    "\n",
    "Having that criteria in mind, [Bosse and Zlot [2009a]](https://www.sciencedirect.com/science/article/abs/pii/S0921889009000992) present results showing that keeping a representative point per curvature cluster is better than segment centroids and mean-shift for 2D point clouds.\n",
    "Also, [Gelfand et al. [2003]](https://ieeexplore.ieee.org/document/1240258) propose a sampling method selecting points leading to a better geometric stability of the minimization. \n",
    "Relying on non-geometric information, [Druon et al. [2006]](https://ieeexplore.ieee.org/document/4097937) use seven clusters based on hue values and select only one cluster carrying the most information for registration. \n",
    "The same type of solution was previously presented before by [Godin et al. [1994]](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/2350/1/Three-dimensional-registration-using-range-and-intensity-information/10.1117/12.189139.short), who clustered point based on laser intensity values.\n",
    "\n",
    "It is also possible to find more application-specific methods in the literature. \n",
    "For example, the tip of the nose, inner corners of the eyes, and nose corners are directly extracted for face detection [[Pan et al., 2010]](https://ieeexplore.ieee.org/document/5476132). \n",
    "In medical imagery, blood vessel crossings are also used to reduce features. \n",
    "Moreover, the main orientation of the blood vessel crossings and its number of branching is used to construct descriptors [[Stewart et al., 2003]](https://ieeexplore.ieee.org/document/1242341).\n",
    "The complete point cloud can also be reduced to its first and second statistical moments [[Liu, 2010]](https://ieeexplore.ieee.org/document/5291420) or with orientation and projection histograms [[Bosse and Zlot, 2008]](https://journals.sagepub.com/doi/10.1177/0278364908091366)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor Noise\n",
    "Sensor noise is also taken into account at this stage of the process.\n",
    "Models representing noises are intended to evaluate the uncertainty of a measured point based on the limitations of the sensor used.\n",
    "They may try to identify if a point is a measurement artifact or how accurately the position is measured.\n",
    "To cope with stereo reconstruction noise, [Diebel et al. [2004]](https://ieeexplore.ieee.org/document/1389948) remove points with distance and surface angle to neighbors larger than two times the median of all distances and surface angles within the point cloud. \n",
    "When using laser's remission intensity, which is not invariant to distance and angle, [Yoshitaka et al. [2006]](https://ieeexplore.ieee.org/document/4153430) propose to keep points only close to the laser to reduce the impact of distance on the intensity value. \n",
    "For color images, points with low saturation value tend to be gray and are removed before applying clustering technique based on hue [[Druon et al., 2006]](https://ieeexplore.ieee.org/document/4097937). \n",
    "Points on boundaries of the sensor reading can also be removed to avoid misleading interpretation of neighbor points [[Armesto et al., 2010]](https://ieeexplore.ieee.org/document/5509371).\n",
    "When an error model is available, it is also possible to add noise information based on measurement distance, incidence angle, reflectivity, etc.\n",
    "Examples of noise models on distance reading are investigated for Sick LMS-151, Hokuyo URG and UTM in [[Pomerleau et al., 2012a]](https://ieeexplore.ieee.org/document/6473358).\n",
    "\n",
    "## Example 1\n",
    "The simplest of the filters is a random subsampling in order to decimate the point cloud:\n",
    "\n",
    "$$\n",
    "    \\shape{P'} = \\datafilter(\\shape{P}) = \\left\\{\\point{p} \\in \\shape{P}: \\eta(\\point{p})<\\theta\\right\\}\n",
    "$$\n",
    "\n",
    "where $\\eta\\in[0,1)$ is a uniform-distributed random value and $\\theta\\in[0,1]$ a fixed threshold, corresponding to the fraction of points to keep.\n",
    "\n",
    "## Example 2\n",
    "A second example is the computation of normal vectors in a point cloud:\n",
    "\n",
    "$$\n",
    "    \\shape{P'} = \\datafilter(\\shape{P}) = \\left\\{\n",
    "        \\left[\\begin{array}{c}\\point{p}\\\\n\\end{array}\\right]:\n",
    "        \\forall\\point{p} \\in \\shape{P}, n=\\text{normal}(\\point{p})\n",
    "    \\right\\}\n",
    "$$\n",
    "\n",
    "where $\\text{normal}(\\point{p})$ is the normal vector inferred around point $\\point{p}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
